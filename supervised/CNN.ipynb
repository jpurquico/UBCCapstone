{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model\n",
    "### CNN model cited from 585 tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/Vaccine pages.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.data import Field, LabelField\n",
    "from torchtext.data import TabularDataset\n",
    "import spacy\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "import csv \n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df = df[df['Tags confirmed']=='checked'] # only read the ones are checkd\n",
    "train_df, dev_df = train_test_split(df, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Vaccines page pairs EN/FR</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Refining details</th>\n",
       "      <th>Tags confirmed</th>\n",
       "      <th>Status</th>\n",
       "      <th>Issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>6089e6208ae21611fc74db07</td>\n",
       "      <td>2021年4月28日</td>\n",
       "      <td>Authorized vaccines EN/FR</td>\n",
       "      <td>Where do I get the right vaccine for my age gr...</td>\n",
       "      <td>Getting vaccinated - When / Where / What</td>\n",
       "      <td>Where to get vaccinated near me</td>\n",
       "      <td>checked</td>\n",
       "      <td>New</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4943</th>\n",
       "      <td>6094192e82338d0ecce56cb9</td>\n",
       "      <td>2021年5月6日</td>\n",
       "      <td>Authorized vaccines EN/FR</td>\n",
       "      <td>I asked for FDA approved vaccines but the FDA ...</td>\n",
       "      <td>Vaccine strategy: Authorization / Eligibility ...</td>\n",
       "      <td>Vaccine agreements / authorizations / other va...</td>\n",
       "      <td>checked</td>\n",
       "      <td>New</td>\n",
       "      <td>Approval of vaccines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>6091458c82338d0ecce564a0</td>\n",
       "      <td>2021年5月4日</td>\n",
       "      <td>Vaccine safety, concerns and possible side eff...</td>\n",
       "      <td>i wanted to find out about SERIOUS side effect...</td>\n",
       "      <td>Vaccine safety (health issues / ingredients / ...</td>\n",
       "      <td>Side effects: possible</td>\n",
       "      <td>checked</td>\n",
       "      <td>New</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>6094718a82338d0ecce56e1a</td>\n",
       "      <td>2021年5月6日</td>\n",
       "      <td>AstraZeneca: What you should know EN/FR</td>\n",
       "      <td>On me dit que les compagnies de vaccins ne son...</td>\n",
       "      <td>Vaccines - Other</td>\n",
       "      <td>Other - Vaccines</td>\n",
       "      <td>checked</td>\n",
       "      <td>New</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>609135d882338d0ecce56476</td>\n",
       "      <td>2021年5月4日</td>\n",
       "      <td>How to get vaccinated EN/FR</td>\n",
       "      <td>Where can I get vaccinted</td>\n",
       "      <td>Getting vaccinated - When / Where / What</td>\n",
       "      <td>Where to get vaccinated near me</td>\n",
       "      <td>checked</td>\n",
       "      <td>New</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Unique ID        Date  \\\n",
       "2266  6089e6208ae21611fc74db07  2021年4月28日   \n",
       "4943  6094192e82338d0ecce56cb9   2021年5月6日   \n",
       "4672  6091458c82338d0ecce564a0   2021年5月4日   \n",
       "5268  6094718a82338d0ecce56e1a   2021年5月6日   \n",
       "2366  609135d882338d0ecce56476   2021年5月4日   \n",
       "\n",
       "                              Vaccines page pairs EN/FR  \\\n",
       "2266                          Authorized vaccines EN/FR   \n",
       "4943                          Authorized vaccines EN/FR   \n",
       "4672  Vaccine safety, concerns and possible side eff...   \n",
       "5268            AstraZeneca: What you should know EN/FR   \n",
       "2366                        How to get vaccinated EN/FR   \n",
       "\n",
       "                                                Comment  \\\n",
       "2266  Where do I get the right vaccine for my age gr...   \n",
       "4943  I asked for FDA approved vaccines but the FDA ...   \n",
       "4672  i wanted to find out about SERIOUS side effect...   \n",
       "5268  On me dit que les compagnies de vaccins ne son...   \n",
       "2366                         Where can I get vaccinted    \n",
       "\n",
       "                                                   Tags  \\\n",
       "2266           Getting vaccinated - When / Where / What   \n",
       "4943  Vaccine strategy: Authorization / Eligibility ...   \n",
       "4672  Vaccine safety (health issues / ingredients / ...   \n",
       "5268                                   Vaccines - Other   \n",
       "2366           Getting vaccinated - When / Where / What   \n",
       "\n",
       "                                       Refining details Tags confirmed Status  \\\n",
       "2266                    Where to get vaccinated near me        checked    New   \n",
       "4943  Vaccine agreements / authorizations / other va...        checked    New   \n",
       "4672                             Side effects: possible        checked    New   \n",
       "5268                                  Other - Vaccines         checked    New   \n",
       "2366                    Where to get vaccinated near me        checked    New   \n",
       "\n",
       "                     Issue  \n",
       "2266                   NaN  \n",
       "4943  Approval of vaccines  \n",
       "4672                   NaN  \n",
       "5268                   NaN  \n",
       "2366                   NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(df, path):\n",
    "    \"\"\"\n",
    "    write csv file for each split given path\n",
    "        df: dataframe\n",
    "        path: path to the dataframe\n",
    "    \"\"\"\n",
    "    tag_id = 0\n",
    "    rows = []\n",
    "    with open(path, 'w') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(['comment','tag'])\n",
    "        for idex, row in df.iterrows():\n",
    "            rows.append([row[\"Comment\"], row[\"Tags\"]])\n",
    "            tag_id += 1\n",
    "        csvwriter.writerows(rows)\n",
    "\n",
    "write_csv(train_df, \"../data/vaccine_train.csv\")\n",
    "write_csv(dev_df, \"../data/vaccine_dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitespace_tokenizer(text):\n",
    "    \"\"\"\n",
    "    Split the text by white space\n",
    "    text: str\n",
    "    return: list fo tokens\n",
    "    \"\"\"\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(sequential=True, tokenize=whitespace_tokenizer, lower=True)\n",
    "LABEL = Field(sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and val\n",
    "train, val = TabularDataset.splits(\n",
    "               path=\"../data/\", # the root directory where the data lies\n",
    "               train=\"vaccine_train.csv\", validation=\"vaccine_dev.csv\", # file names\n",
    "               format='csv',\n",
    "               skip_header=True, # if your tsv file has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
    "               fields=[('comment', TEXT), ('tag', LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['comment', 'tag'])\n",
      "['where', 'do', 'i', 'get', 'the', 'right', 'vaccine', 'for', 'my', 'age', 'group?']\n",
      "Getting vaccinated - When / Where / What\n"
     ]
    }
   ],
   "source": [
    "# take a look at one instance\n",
    "print(train[0].__dict__.keys())\n",
    "print(train[0].comment)\n",
    "print(train[0].tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train)\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = len(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 1: ['where', 'do', 'i', 'get', 'the', 'right', 'vaccine', 'for', 'my', 'age', 'group?']\n",
      "token 2: ['where', 'do', 'i', 'get', 'vaccine?']\n",
      "tensor([[  28,   28],\n",
      "        [  23,   23],\n",
      "        [   2,    2],\n",
      "        [  11,   11],\n",
      "        [   3,   76],\n",
      "        [ 382,    1],\n",
      "        [   5,    1],\n",
      "        [   6,    1],\n",
      "        [  13,    1],\n",
      "        [  97,    1],\n",
      "        [1664,    1]])\n",
      "torch.Size([11, 2])\n"
     ]
    }
   ],
   "source": [
    "token_1 = TEXT.preprocess('where do i get the right vaccine for my age group?')\n",
    "print(\"token 1:\", token_1)\n",
    "token_2 = TEXT.preprocess('where do i get vaccine?')\n",
    "print(\"token 2:\", token_2)\n",
    "# convert tokens to tensor\n",
    "tensor = TEXT.process([token_1,token_2])\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linxuanyang/opt/miniconda3/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_iter, val_iter = BucketIterator.splits(\n",
    " (train, val), \n",
    " batch_sizes=(64,64), # batch size for train and val\n",
    " sort_key=lambda x: len(x.comment), \n",
    " sort=True,\n",
    " sort_within_batch=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for batch in train_iter: # seq len, batch size \n",
    "    comments = batch.comment\n",
    "    tags = batch.tag\n",
    "    print(comments.shape)\n",
    "    print(tags.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Text(nn.Module):\n",
    "    def __init__(self, vocabulary_size, embedding_dim, output_size, kernel_num, region_sizes, dropout):\n",
    "        '''\n",
    "        vocabulary_size: vocabulary size\n",
    "        embedding_dim: word embedding size\n",
    "        output_size: number of classes in prediction\n",
    "        kernel_num: number of kernels (number of output channels of convolutional layers)\n",
    "        region_sizes: height of kernels of convolutional layers\n",
    "        dropout: dropout rate\n",
    "        '''\n",
    "        super(CNN_Text, self).__init__()\n",
    "        # the size of input channel is 1.\n",
    "        Ci = 1\n",
    "        \n",
    "        # word embedding layer\n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size, embedding_dim = embedding_dim )\n",
    "        \n",
    "        # convolution with kernels\n",
    "        self.convolution_layers = nn.ModuleList([nn.Conv2d(in_channels = Ci, out_channels = kernel_num, kernel_size = (K, embedding_dim)) for K in region_sizes])\n",
    "        \n",
    "        # a dropout layer\n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "        \n",
    "        # fully connected layer\n",
    "        self.fc = nn.Linear(len(kernel_sizes) * kernel_num, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input x  [sequence length, batch size]\n",
    "        \n",
    "        input_embeddings = self.embeddings(x)  \n",
    "        # (batch size, word_sequence, embedding_dim) word embedding\n",
    "\n",
    "        input_embeddings = input_embeddings.permute(1,0,2)\n",
    "        input_embeddings = input_embeddings.unsqueeze(1)\n",
    "        #  [batch size, number of channel is one, sequence length, embeeding size]\n",
    "\n",
    "        # convolutional layers\n",
    "        convolute_outputs = [F.relu(conv(input_embeddings)).squeeze(3) for conv in self.convolution_layers]  \n",
    "        \n",
    "        # to get the maximum value of filtered tensor\n",
    "        max_pooling_outputs = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in convolute_outputs] \n",
    "        \n",
    "        concat_list = torch.cat(max_pooling_outputs, 1) # concatenate representations\n",
    "        \n",
    "        drop_output = self.dropout(concat_list)  # add drop layer\n",
    "        \n",
    "        fc1_output = self.fc(drop_output)  # get the fc1 using a fully connected layer\n",
    "        \n",
    "        final_output = F.softmax(fc1_output,dim=1)\n",
    "        \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "\n",
    "# the vocabulary size\n",
    "vocabulary_size = len(TEXT.vocab.stoi) \n",
    "\n",
    "# Dimension of word embedding is 300. Namely, each word is expressed by a vector that has 300 dimensions.\n",
    "embedding_dim = 300 \n",
    "\n",
    "# region size as 2, 3, and 4\n",
    "kernel_sizes = [1,2]#[2,3,4] \n",
    "\n",
    "# the number of kernel in each region size\n",
    "kernels_num = 32  \n",
    "\n",
    "# The dropout rate is set to be 0.5.\n",
    "dropout = 0.5\n",
    "\n",
    "# The output size of labels.\n",
    "output_size = output_size\n",
    "\n",
    "# learning rate is set to be 0.01.\n",
    "lr = 0.01        \n",
    "\n",
    "# The number of iteration is set to be 5.\n",
    "num_epoch = 5  \n",
    "\n",
    "# employ class CNN_Text and assign to cnn\n",
    "model = CNN_Text(vocabulary_size, embedding_dim, output_size, kernels_num, kernel_sizes, dropout)\n",
    "#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Text(\n",
       "  (embeddings): Embedding(8063, 300)\n",
       "  (convolution_layers): ModuleList(\n",
       "    (0): Conv2d(1, 32, kernel_size=(2, 300), stride=(1, 1))\n",
       "    (1): Conv2d(1, 32, kernel_size=(3, 300), stride=(1, 1))\n",
       "    (2): Conv2d(1, 32, kernel_size=(4, 300), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=96, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.1)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)   # define a optimizer for backpropagation\n",
    "loss_func = nn.CrossEntropyLoss()   # define loss funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        batch_input, labels = batch.comment, batch.tag\n",
    "        batch_input = batch_input#.to(device)\n",
    "        labels = labels#.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(batch_input)\n",
    "        #print(outputs.shape)\n",
    "        #print(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.cpu().item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    all_pred=[]\n",
    "    all_label = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            batch_input, labels = batch.comment, batch.tag\n",
    "            batch_input = batch_input#.to(device)\n",
    "            labels = labels#.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(batch_input)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            epoch_loss += loss.cpu().item()\n",
    "\n",
    "            # identify the predicted class for each example in the batch\n",
    "            probabilities, predicted = torch.max(outputs.cpu().data, 1)\n",
    "            # put all the true labels and predictions to two lists\n",
    "            all_pred.extend(predicted)\n",
    "            all_label.extend(labels.cpu())\n",
    "    \n",
    "    accuracy = accuracy_score(all_label, all_pred)\n",
    "    f1score = f1_score(all_label, all_pred, average='macro') \n",
    "    return epoch_loss / len(iterator), accuracy, f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   7%|▋         | 1/15 [00:01<00:21,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [1/15], Train Loss: 2.1714, Validation Loss: 2.1681, Validation Accuracy: 0.1976, Validation F1: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  13%|█▎        | 2/15 [00:02<00:18,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [2/15], Train Loss: 2.1722, Validation Loss: 2.1681, Validation Accuracy: 0.1976, Validation F1: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 3/15 [00:04<00:17,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [3/15], Train Loss: 2.1735, Validation Loss: 2.1681, Validation Accuracy: 0.1976, Validation F1: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  27%|██▋       | 4/15 [00:05<00:15,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [4/15], Train Loss: 2.1709, Validation Loss: 2.1681, Validation Accuracy: 0.1976, Validation F1: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 5/15 [00:06<00:13,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [5/15], Train Loss: 2.1731, Validation Loss: 2.1681, Validation Accuracy: 0.1976, Validation F1: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 6/15 [00:08<00:12,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [6/15], Train Loss: 2.1725, Validation Loss: 2.1681, Validation Accuracy: 0.1976, Validation F1: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  47%|████▋     | 7/15 [00:09<00:11,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [7/15], Train Loss: 2.1736, Validation Loss: 2.1681, Validation Accuracy: 0.1976, Validation F1: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  53%|█████▎    | 8/15 [00:11<00:10,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [8/15], Train Loss: 2.1708, Validation Loss: 2.1681, Validation Accuracy: 0.1976, Validation F1: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 9/15 [00:12<00:09,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [9/15], Train Loss: 2.1739, Validation Loss: 2.1681, Validation Accuracy: 0.1976, Validation F1: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 10/15 [00:14<00:07,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [10/15], Train Loss: 2.1729, Validation Loss: 2.1681, Validation Accuracy: 0.1976, Validation F1: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  73%|███████▎  | 11/15 [00:15<00:05,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [11/15], Train Loss: 2.1718, Validation Loss: 2.1681, Validation Accuracy: 0.1976, Validation F1: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 12/15 [00:17<00:04,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [12/15], Train Loss: 2.1727, Validation Loss: 2.1681, Validation Accuracy: 0.1976, Validation F1: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  87%|████████▋ | 13/15 [00:18<00:02,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [13/15], Train Loss: 2.1722, Validation Loss: 2.1681, Validation Accuracy: 0.1976, Validation F1: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  93%|█████████▎| 14/15 [00:20<00:01,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [14/15], Train Loss: 2.1723, Validation Loss: 2.1681, Validation Accuracy: 0.1976, Validation F1: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 15/15 [00:21<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch [15/15], Train Loss: 2.1727, Validation Loss: 2.1681, Validation Accuracy: 0.1976, Validation F1: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCH = 15\n",
    "total_step = len(train_iter)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "\n",
    "for epoch in trange(MAX_EPOCH, desc=\"Epoch\"):\n",
    "    train_loss = train(model, train_iter, optimizer, loss_func)  \n",
    "    val_loss, val_acc, val_f1 = evaluate(model, val_iter, loss_func)\n",
    "\n",
    "    # Create checkpoint at end of each epoch\n",
    "    state_dict_model = model.state_dict() \n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'state_dict': state_dict_model,\n",
    "        'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "\n",
    "    torch.save(state, \"../data/ckpt_cnn/CNN_TEXT_\"+str(epoch+1)+\".pt\")\n",
    "\n",
    "    print('\\n Epoch [{}/{}], Train Loss: {:.4f}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, Validation F1: {:.4f}'.format(epoch+1, MAX_EPOCH, train_loss, val_loss, val_acc, val_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
